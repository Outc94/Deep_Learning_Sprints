{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 12 - Convolutional Neural Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) \n",
    "print(y_train_one_hot.shape) \n",
    "print(y_train_one_hot.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train---> (48000, 784)\n",
      "X_val---> (12000, 784)\n",
      "y_train---> (48000, 10)\n",
      "y_val---> (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(\"X_train--->\", X_train_.shape) \n",
    "print(\"X_val--->\", X_val.shape)  \n",
    "print(\"y_train--->\", y_train_.shape) \n",
    "print(\"y_val--->\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=20)\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    mini_X_train, mini_y_train\n",
    "mini_X_train = mini_X_train.reshape(20, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self,f_num, Chanel, f_size_h, f_size_w):\n",
    "        np.random.seed(0)\n",
    "        self.W = self.sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
    "        return self.W\n",
    "    \n",
    "    def B(self, f_num):\n",
    "        np.random.seed(0)\n",
    "        self.B = self.sigma * np.random.randn(f_num,1)\n",
    "        return self.B\n",
    "\n",
    "class XavierInitializer:\n",
    "    \n",
    "    def __init__(self, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self,f_num, Chanel, f_size_h, f_size_w):\n",
    "        self.sigma = (1 / np.sqrt(f_num))\n",
    "        np.random.seed(0)\n",
    "        self.W = self.sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
    "        return self.W\n",
    "        \n",
    "    def B(self,f_num):\n",
    "        np.random.seed(0)\n",
    "        self.sigma = (1 / np.sqrt(f_num))\n",
    "        self.B = self.sigma * np.random.randn(f_num,1)\n",
    "        return self.B\n",
    "\n",
    "class He:\n",
    "    \n",
    "    def __init__(self, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, f_num, Chanel, f_size_h, f_size_w):\n",
    "        sigma = np.sqrt(2 / 1)\n",
    "        np.random.seed(0)\n",
    "        self.W = sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
    "        return self.W\n",
    "        \n",
    "    def B(self,f_num):\n",
    "        sigma = np.sqrt(2 / 1)\n",
    "        np.random.seed(0)\n",
    "        self.B = sigma * np.random.randn(f_num,1)\n",
    "        return self.B\n",
    "\n",
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self,layer):\n",
    "\n",
    "        layer.W -= (self.lr * layer.dW)\n",
    "        layer.B -= (self.lr * layer.dB)\n",
    "        return layer.W, layer.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the Size (Height and Width) of the Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_heigh_calculation(X_h,pad_n,F_h,stride):\n",
    "    output_h = (X_h + 2*pad_n - F_h)//stride + 1\n",
    "    return output_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_width_calculation(X_w,pad_n,F_w,stride):\n",
    "    output_w = (X_w + 2*pad_n - F_w)//stride + 1\n",
    "    return output_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = output_heigh_calculation(X_h=H,pad_n=pad, F_h=filter_h, stride=stride)\n",
    "    out_w = output_width_calculation(X_w=W,pad_n=pad, F_w=filter_w, stride=stride)\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, X, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = X.shape\n",
    "    out_h = output_heigh_calculation(X_h=H,pad_n=pad, F_h=filter_h, stride=stride)\n",
    "    out_w = output_width_calculation(X_w=W,pad_n=pad, F_w=filter_w, stride=stride)\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, the two dimensional convolutional layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv2d:\n",
    "    \n",
    "    def __init__(self, f_num=1, f_size_h=2, f_size_w=2, stride=1, pad = 1, initializer=XavierInitializer(), optimizer=SGD(lr=0.05)):\n",
    "\n",
    "        self.f_num = f_num\n",
    "        self.f_size_h = f_size_h\n",
    "        self.f_size_w = f_size_w\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        self.kernel  = None\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.W = None\n",
    "        self.B = None \n",
    "        \n",
    "    def im2col(self, input_data):\n",
    "        N, C, H, W = input_data.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h= self.f_size_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
    "        img = np.pad(input_data, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
    "        col = np.zeros((N, C, self.f_size_h, self.f_size_w, out_h, out_w))\n",
    "\n",
    "        for y in range(self.f_size_h):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(self.f_size_w):\n",
    "                x_max = x + self.stride*out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.stride, x:x_max:self.stride]\n",
    "\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "        return col\n",
    "    \n",
    "    def col2im(self, col, X):\n",
    "        N, C, H, W = X.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.f_size_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
    "        col = col.reshape(N, out_h, out_w, C, self.f_size_h, self.f_size_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        img = np.zeros((N, C, H + 2*self.pad + self.stride - 1, W + 2*self.pad + self.stride - 1))\n",
    "        \n",
    "        for y in range(self.f_size_h):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(self.f_size_w):\n",
    "                x_max = x + self.stride*out_w\n",
    "                img[:, :, y:y_max:self.stride, x:x_max:self.stride] += col[:, :, y, x, :, :]\n",
    "        return img[:, :, self.pad:H + self.pad, self.pad:W + self.pad]\n",
    "        \n",
    "    def forward(self,X):\n",
    "        if self.W is None:\n",
    "            self.W = self.initializer.W(self.f_num, X.shape[1], self.f_size_h , self.f_size_w)\n",
    "        if self.B is None:\n",
    "            self.B = self.initializer.B(self.f_num)\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = X.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.f_size_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
    "            \n",
    "        self.col = self.im2col(X)\n",
    "        self.col_W = self.W.reshape(FN, -1).T\n",
    "        out = np.dot(self.col, self.col_W) + self.B.T\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
    "        self.X = X\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "        self.dB = np.sum(dout, axis=0).reshape(self.f_num,1)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        self.dx = self.col2im(dcol,self.X)\n",
    "        \n",
    "        return self.dx\n",
    "        self = self.optimizer.update(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SimpleConv2d(f_num=3, f_size_h=3,  f_size_w=3, stride=1, pad=1, initializer=SimpleInitializer())\n",
    "testing = test.forward(mini_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
       "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         ...,\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
       "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
       "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
       "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backward(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 28, 28)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backward(testing).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maximum Pooling Layer (MaxPool2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \n",
    "    def __init__(self, P_h, P_w, stride=1, pad=0):\n",
    "        self.P_h = P_h\n",
    "        self.P_w = P_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "        \n",
    "    def im2col(self, input_data):\n",
    "        N, C, H, W = input_data.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h= self.P_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
    "        img = np.pad(input_data, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
    "        col = np.zeros((N, C, self.P_h, self.P_w, out_h, out_w))\n",
    "\n",
    "        for y in range(self.P_h):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(self.P_w):\n",
    "                x_max = x + self.stride*out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.stride, x:x_max:self.stride]\n",
    "\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "        return col\n",
    "    \n",
    "    def col2im(self, col, X):\n",
    "        N, C, H, W = X.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.P_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
    "        col = col.reshape(N, out_h, out_w, C, self.P_h, self.P_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        img = np.zeros((N, C, H + 2*self.pad + self.stride - 1, W + 2*self.pad + self.stride - 1))\n",
    "        \n",
    "        for y in range(self.P_h):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(self.P_w):\n",
    "                x_max = x + self.stride*out_w\n",
    "                img[:, :, y:y_max:self.stride, x:x_max:self.stride] += col[:, :, y, x, :, :]\n",
    "        return img[:, :, self.pad:H + self.pad, self.pad:W + self.pad]\n",
    "       \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.P_h, stride=self.stride)\n",
    "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
    "        col = self.im2col(x)     \n",
    "        col = col.reshape(-1, self.P_h*self.P_w)\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)    \n",
    "        p_size = self.P_h * self.P_w\n",
    "        dmax = np.zeros((dout.size, p_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (p_size,))     \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = self.col2im(dcol, self.x)\n",
    "        return dx\n",
    "        self = self.optimizer.update(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = MaxPool2D( P_h=2, P_w=2, stride=2, pad=0)\n",
    "testing2 = test2.forward(testing)\n",
    "testing22 = test2.backward(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 7, 7)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 15, 15)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing22.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out = x.reshape(N, -1)        \n",
    "        self.x = x        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout.reshape(self.x.shape)      \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial---> (20, 1, 15, 15)\n",
      "Forward--> (20, 225)\n",
      "Backward--> (20, 1, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "smoothing = Flatten()\n",
    "smoothing_f = smoothing.forward(testing)\n",
    "smoothing_b = smoothing.backward(smoothing_f)\n",
    "print(f'Initial---> {testing.shape}')\n",
    "print(f'Forward--> {fl_out.shape}')\n",
    "print(f'Backward--> {fl_dx.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        self.optimizer = optimizer\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def forward(self, X): \n",
    "        self.Z = X\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    \n",
    "    def forward(self, A): \n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, Z, y):\n",
    "        dA = Z - y\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss\n",
    "    \n",
    "class AdaGrad:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr \n",
    "    \n",
    "    def update(self, layer):\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 \n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer\n",
    "\n",
    "class HeInitializer:\n",
    "\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B\n",
    "\n",
    "class Relu:\n",
    "\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D2:\n",
    "\n",
    "    def __init__(self, P_h, P_w, pad=0):\n",
    "        self.P_h = P_h\n",
    "        self.P_w = P_w\n",
    "        self.stride = P_h\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.P_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.P_w) / self.stride)\n",
    "        col = im2col(x, self.P_h, self.P_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.P_h*self.P_w)\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)    \n",
    "        pool_size = self.P_h * self.P_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,))       \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.P_h, self.P_w, self.stride, self.pad)    \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch2dCNNClassifier:\n",
    "\n",
    "    def __init__(self, FN=20, FH=7, FW=7, stride=1, pad=0, epoch=1, optimizer=AdaGrad, initializer=HeInitializer, activater=Relu, verbose=False,):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = 60 \n",
    "        self.n_output = 10 \n",
    "        self.sigma = 0.02 \n",
    "        self.lr = 0.05 \n",
    "        self.epoch = epoch \n",
    "        self.optimizer = optimizer \n",
    "        self.initializer = initializer \n",
    "        self.activater = activater \n",
    "        self.FN = FN \n",
    "        self.C = 1 \n",
    "        self.FH = FH \n",
    "        self.FW = FW \n",
    "        self.pool_h = 2 \n",
    "        self.pool_w = 2 \n",
    "        self.pad = pad \n",
    "        self.stride = stride \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.loss_train = [] \n",
    "        self.loss_val = []   \n",
    "        out_h, out_w = self.out_size(28, 28, self.pad, self.FH, self.FW, self.stride)\n",
    "        out_h, out_w = self.out_size(out_h, out_w, 0, self.pool_h, self.pool_w, self.pool_h)\n",
    "        fc_nodes = self.FN * out_h * out_w \n",
    "        optimizer = self.optimizer(self.lr)    \n",
    "        w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
    "        b = self.sigma * np.random.randn(self.FN,)\n",
    "        self.cv= SimpleConv2d(self.FN, self.FH, self.FW, self.stride, self.pad, initializer=SimpleInitializer())\n",
    "        self.activation_cv = self.activater()\n",
    "        self.pl = MaxPool2D2(self.pool_h, self.pool_w)\n",
    "        self.fl = Flatten()\n",
    "        self.FC = FC(fc_nodes, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation_fc = SoftmaxWithLoss()\n",
    "\n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                \n",
    "                A1 = self.cv.forward(mini_X)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "                P1 = self.pl.forward(Z1)\n",
    "                F1 = self.fl.forward(P1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.activation_fc.forward(A2)\n",
    "\n",
    "                dA2, loss = self.activation_fc.backward(Z2, mini_y) \n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dF1 = self.fl.backward(dZ2)\n",
    "                dP1 = self.pl.backward(dF1)\n",
    "                dA1 = self.activation_cv.backward(dP1)\n",
    "                dZ1 = self.cv.backward(dA1)\n",
    "\n",
    "            if self.verbose:\n",
    "                A1 = self.cv.forward(X)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "                P1 = self.pl.forward(Z1)\n",
    "                F1 = self.fl.forward(P1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.activation_fc.forward(A2)  \n",
    "                self.loss_train.append(self.activation_fc.backward(Z2, y)[1])\n",
    "                \n",
    "                if X_val is not None:\n",
    "                    A1 = self.cv.forward(X_val)\n",
    "                    Z1 = self.activation_cv.forward(A1)\n",
    "                    P1 = self.pl.forward(Z1)\n",
    "                    F1 = self.fl.forward(P1)\n",
    "                    A2 = self.FC.forward(F1)\n",
    "                    Z2 = self.activation_fc.forward(A2)         \n",
    "                    self.loss_val.append(self.activation_fc.backward(Z2, y_val)[1])\n",
    "                    \n",
    "    def out_size(self, H, W, P, FH, FW, S):\n",
    "        out_h = (H + 2 * P - FH) // S + 1\n",
    "        out_w = (W + 2 * P - FW) // S + 1\n",
    "        return out_h, out_w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        A1 = self.cv.forward(X)\n",
    "        Z1 = self.activation_cv.forward(A1)\n",
    "        P1 = self.pl.forward(Z1)\n",
    "        F1 = self.fl.forward(P1)\n",
    "        A2 = self.FC.forward(F1)\n",
    "        Z2 = self.activation_fc.forward(A2)\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2dCNN = Scratch2dCNNClassifier(FN=5, FH=7, FW=7, stride=1, pad=2, epoch=1, verbose=True)\n",
    "S2dCNN.fit(X_train, y_train_one_hot, X_val, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6259166666666667"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = S2dCNN.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A higher accuracy can be obtained with a high epoch and filter numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size(H, W, P, FH, FW, S):\n",
    "    out_h = (H + 2 * P - FH) // S + 1\n",
    "    out_w = (W + 2 * P - FW) // S + 1\n",
    "    return out_h, out_w\n",
    "\n",
    "def number_of_parameters(FH, FW, C, FN):\n",
    "    return FH*FW*C*FN + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = output_size(144, 144, 0, 3, 3, 1)\n",
    "test2 = number_of_parameters(3, 3, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 142)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = output_size(60, 60, 0, 3, 3, 1)\n",
    "test4 = number_of_parameters(3, 3, 24, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 58)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10416"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 = output_size(20, 20, 0, 3, 3, 2)\n",
    "test6 = number_of_parameters(3, 3, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
